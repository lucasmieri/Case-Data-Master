{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "1.Read and Analyze Data\n",
      "\n",
      "\n",
      "Reading members.parquet\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Reading file: c:\\Users\\Lucas\\OneDrive\\case data master\\data\\raw\\members.parquet\n",
      "\n",
      "\n",
      "The column 'msno' is already the type 'string'.\n",
      "\n",
      "\n",
      "The column 'safra' is already the type 'string'.\n",
      "\n",
      "\n",
      "Converting column 'registration_init_time' from type string to 'datetime64[ns]'.\n",
      "\n",
      "\n",
      "Column 'registration_init_time' successfully converted to type 'datetime64[ns]'.\n",
      "\n",
      "\n",
      "The column 'city' is already the type 'string'.\n",
      "\n",
      "\n",
      "Converting column 'bd' from type string to 'int16'.\n",
      "\n",
      "\n",
      "Column 'bd' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "Converting column 'gender' from type string to 'float16'.\n",
      "\n",
      "\n",
      "The column 'registered_via' is already the type 'string'.\n",
      "\n",
      "\n",
      "Converting column 'is_ativo' from type int32 to 'int16'.\n",
      "\n",
      "\n",
      "Column 'is_ativo' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "--- Analyzing members.parquet DataFrame ---\n",
      "\n",
      "\n",
      "Displaying first 10 rows of the DataFrame:\n",
      "\n",
      "\n",
      "\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|    | msno                                         |   safra | registration_init_time   |   city |   bd |   gender |   registered_via |   is_ativo |\n",
      "+====+==============================================+=========+==========================+========+======+==========+==================+============+\n",
      "|  0 | +++snpr7pmobhLKUgSHTv/mpkqgBT0tQJ0zQj6qKrqc= |  201612 | 2014-09-27 00:00:00      |      1 |  nan |      nan |                7 |          1 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  1 | ++/AwGzubug3gT6J+0STBGMdWKxaM+UFZTI8Tcmq4To= |  201607 | 2015-03-22 00:00:00      |      1 |  nan |      nan |                9 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  2 | ++/Gw1B9K+XOlB3hLTloeUK2QlCa2m+BJ8TrzGf7djI= |  201601 | 2012-12-17 00:00:00      |     15 |   32 |        1 |                3 |          1 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  3 | ++02XbtviomSxcIBUHMOiJkjRxdicTXSfiVqLdsr5lo= |  201603 | 2013-11-12 00:00:00      |     14 |   21 |        1 |                7 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  4 | ++0O0Bq04sB/9ZcOS+pajpYL2Hin9jCqnc/8bKzKFuE= |  201610 | 2014-10-21 00:00:00      |      5 |   33 |        1 |                3 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  5 | ++2AQgVgYUAqJDw684tbDqDffUeKhqydyQmbr8lz9lQ= |  201608 | 2015-04-16 00:00:00      |     18 |   23 |        1 |                3 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  6 | ++2gRJ7i2MbO6qUG6rGfFnu/Fcv+hdX4YvTkZD+PUsk= |  201608 | 2014-06-16 00:00:00      |     11 |   33 |        1 |                7 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  7 | ++3brN43Yd6GURegTBR85oMQcJrgW1+/N4B8Rjj75fY= |  201604 | 2010-05-12 00:00:00      |     14 |   19 |        1 |                9 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  8 | ++4FwgRp7pHuuQWpaUFrCTgJbXVwNTTQpLB2bM1A3lU= |  201605 | 2014-10-10 00:00:00      |      1 |  nan |      nan |                9 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "|  9 | ++4KsBMCDgIrwmv5w2g2cCXhzCsJwDyB5r96/FrwGek= |  201604 | 2014-10-31 00:00:00      |      1 |  nan |      nan |                9 |          0 |\n",
      "+----+----------------------------------------------+---------+--------------------------+--------+------+----------+------------------+------------+\n",
      "\n",
      "\n",
      "\n",
      "Data types of columns in members.parquet:\n",
      "\n",
      "\n",
      "msno                      string[pyarrow]\n",
      "safra                     string[pyarrow]\n",
      "registration_init_time     datetime64[ns]\n",
      "city                      string[pyarrow]\n",
      "bd                                  int16\n",
      "gender                            float16\n",
      "registered_via            string[pyarrow]\n",
      "is_ativo                            int16\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Summary statistics for numeric columns: ['bd', 'gender', 'is_ativo']\n",
      "\n",
      "\n",
      "\n",
      "+-------+----------------+-------------+-------------+\n",
      "|       |             bd |      gender |    is_ativo |\n",
      "+=======+================+=============+=============+\n",
      "| count |    2.43543e+07 | 2.56571e+07 | 6.38672e+07 |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| mean  |   30.0185      | 0.509623    | 0.176035    |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| std   |   16.135       | 0.499907    | 0.38085     |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| min   |    1           | 0           | 0           |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| 25%   |   22           | 0           | 0           |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| 50%   |   27           | 1           | 0           |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| 75%   |   36           | 1           | 0           |\n",
      "+-------+----------------+-------------+-------------+\n",
      "| max   | 2016           | 1           | 1           |\n",
      "+-------+----------------+-------------+-------------+\n",
      "\n",
      "\n",
      "\n",
      "Missing values and their proportions per column:\n",
      "\n",
      "\n",
      "\n",
      "+------------------------+-----------------+--------------------------+\n",
      "|                        |   Missing Count |   Missing Percentage (%) |\n",
      "+========================+=================+==========================+\n",
      "| msno                   |     0           |                   0      |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| safra                  |     0           |                   0      |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| registration_init_time |     0           |                   0      |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| city                   |     0           |                   0      |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| bd                     |     3.95129e+07 |                  61.8673 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| gender                 |     3.82102e+07 |                  59.8275 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| registered_via         |     0           |                   0      |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| is_ativo               |     0           |                   0      |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "\n",
      "\n",
      "Reading transactions.parquet\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Reading file: c:\\Users\\Lucas\\OneDrive\\case data master\\data\\raw\\transactions.parquet\n",
      "\n",
      "\n",
      "The column 'msno' is already the type 'string'.\n",
      "\n",
      "\n",
      "The column 'payment_method_id' is already the type 'string'.\n",
      "\n",
      "\n",
      "Converting column 'payment_plan_days' from type string to 'int16'.\n",
      "\n",
      "\n",
      "Column 'payment_plan_days' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "Converting column 'plan_list_price' from type string to 'int16'.\n",
      "\n",
      "\n",
      "Column 'plan_list_price' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "Converting column 'actual_amount_paid' from type string to 'int16'.\n",
      "\n",
      "\n",
      "Column 'actual_amount_paid' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "Converting column 'is_auto_renew' from type string to 'int16'.\n",
      "\n",
      "\n",
      "Column 'is_auto_renew' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "Converting column 'transaction_date' from type string to 'datetime64[ns]'.\n",
      "\n",
      "\n",
      "Column 'transaction_date' successfully converted to type 'datetime64[ns]'.\n",
      "\n",
      "\n",
      "Converting column 'membership_expire_date' from type string to 'datetime64[ns]'.\n",
      "\n",
      "\n",
      "Column 'membership_expire_date' successfully converted to type 'datetime64[ns]'.\n",
      "\n",
      "\n",
      "Converting column 'is_cancel' from type string to 'int16'.\n",
      "\n",
      "\n",
      "Column 'is_cancel' successfully converted to type 'int16'.\n",
      "\n",
      "\n",
      "Converting column 'safra' from type int32 to 'string'.\n",
      "\n",
      "\n",
      "Column 'safra' successfully converted to type 'string'.\n",
      "\n",
      "\n",
      "--- Analyzing transactions.parquet DataFrame ---\n",
      "\n",
      "\n",
      "Displaying first 10 rows of the DataFrame:\n",
      "\n",
      "\n",
      "\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|    | msno                                         |   payment_method_id |   payment_plan_days |   plan_list_price |   actual_amount_paid |   is_auto_renew | transaction_date    | membership_expire_date   |   is_cancel |   safra |\n",
      "+====+==============================================+=====================+=====================+===================+======================+=================+=====================+==========================+=============+=========+\n",
      "|  0 | +++IZseRRiQS9aaSkH6cMYU6bGDcxUieAi/tH67sC5s= |                  38 |                 410 |              1788 |                 1788 |               0 | 2015-11-21 00:00:00 | 2017-01-04 00:00:00      |           0 |  201511 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  1 | +++snpr7pmobhLKUgSHTv/mpkqgBT0tQJ0zQj6qKrqc= |                  41 |                  30 |               149 |                  149 |               1 | 2015-05-26 00:00:00 | 2015-06-26 00:00:00      |           0 |  201505 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  2 | +++snpr7pmobhLKUgSHTv/mpkqgBT0tQJ0zQj6qKrqc= |                  41 |                  30 |               149 |                  149 |               1 | 2015-09-26 00:00:00 | 2015-10-26 00:00:00      |           0 |  201509 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  3 | ++/9R3sX37CjxbY/AaGvbwr3QkwElKBCtSvVzhCBDOk= |                  41 |                  30 |               149 |                  149 |               1 | 2016-06-15 00:00:00 | 2016-07-15 00:00:00      |           0 |  201606 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  4 | ++/Gw1B9K+XOlB3hLTloeUK2QlCa2m+BJ8TrzGf7djI= |                  40 |                  31 |               149 |                  149 |               1 | 2015-01-13 00:00:00 | 2015-02-16 00:00:00      |           0 |  201501 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  5 | ++0nOC7BmrUTtcSboRORfg6ZXTajnBDt1f/SEgH6ONo= |                  16 |                  30 |               149 |                  149 |               1 | 2015-10-12 00:00:00 | 2015-11-11 00:00:00      |           0 |  201510 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  6 | ++0t0Uy2D3r1pRVxg28G3r3l5PfhFlCPMGElwHqbYL8= |                  35 |                   7 |                 0 |                    0 |               0 | 2015-06-14 00:00:00 | 2015-06-15 00:00:00      |           0 |  201506 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  7 | ++1eOqCPRmzyBjMGvAJEaurjI1AFz4Mify6fk2eecbY= |                  35 |                   7 |                 0 |                    0 |               0 | 2016-11-01 00:00:00 | 2016-11-08 00:00:00      |           0 |  201611 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  8 | ++2wdWRV3Thy9HZyRJtKxlNsa55oDiDc7arR1guiypc= |                  41 |                  30 |               149 |                    0 |               1 | 2015-10-08 00:00:00 | 2015-10-15 00:00:00      |           1 |  201510 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "|  9 | ++3A6JMzYJeron30GTcDostfXoAl8rTBuB2M8GeVdNU= |                  41 |                  30 |               149 |                  119 |               1 | 2015-06-11 00:00:00 | 2015-07-11 00:00:00      |           0 |  201506 |\n",
      "+----+----------------------------------------------+---------------------+---------------------+-------------------+----------------------+-----------------+---------------------+--------------------------+-------------+---------+\n",
      "\n",
      "\n",
      "\n",
      "Data types of columns in transactions.parquet:\n",
      "\n",
      "\n",
      "msno                      string[pyarrow]\n",
      "payment_method_id         string[pyarrow]\n",
      "payment_plan_days                   int16\n",
      "plan_list_price                     int16\n",
      "actual_amount_paid                  int16\n",
      "is_auto_renew                       int16\n",
      "transaction_date           datetime64[ns]\n",
      "membership_expire_date     datetime64[ns]\n",
      "is_cancel                           int16\n",
      "safra                     string[pyarrow]\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Summary statistics for numeric columns: ['payment_plan_days', 'plan_list_price', 'actual_amount_paid', 'is_auto_renew', 'is_cancel']\n",
      "\n",
      "\n",
      "\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "|       |   payment_plan_days |   plan_list_price |   actual_amount_paid |   is_auto_renew |   is_cancel |\n",
      "+=======+=====================+===================+======================+=================+=============+\n",
      "| count |         2.07122e+07 |       2.07122e+07 |          2.07122e+07 |     2.07122e+07 | 2.07122e+07 |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| mean  |        31.429       |     140.241       |        142.835       |     0.854383    | 0.0328769   |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| std   |        30.5598      |     132.277       |        133.609       |     0.352722    | 0.178314    |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| min   |         0           |       0           |          0           |     0           | 0           |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| 25%   |        30           |      99           |         99           |     1           | 0           |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| 50%   |        30           |     149           |        149           |     1           | 0           |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| 75%   |        30           |     149           |        149           |     1           | 0           |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "| max   |       450           |    2000           |       2000           |     1           | 1           |\n",
      "+-------+---------------------+-------------------+----------------------+-----------------+-------------+\n",
      "\n",
      "\n",
      "\n",
      "Missing values and their proportions per column:\n",
      "\n",
      "\n",
      "\n",
      "+------------------------+-----------------+--------------------------+\n",
      "|                        |   Missing Count |   Missing Percentage (%) |\n",
      "+========================+=================+==========================+\n",
      "| msno                   |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| payment_method_id      |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| payment_plan_days      |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| plan_list_price        |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| actual_amount_paid     |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| is_auto_renew          |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| transaction_date       |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| membership_expire_date |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| is_cancel              |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "| safra                  |               0 |                        0 |\n",
      "+------------------------+-----------------+--------------------------+\n",
      "\n",
      "\n",
      "Reading user_logs.parquet\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Reading file: c:\\Users\\Lucas\\OneDrive\\case data master\\data\\raw\\user_logs.parquet\n",
      "\n",
      "\n",
      "The column 'msno' is already the type 'string'.\n",
      "\n",
      "\n",
      "Converting column 'safra' from type int32 to 'string'.\n",
      "\n",
      "\n",
      "Column 'safra' successfully converted to type 'string'.\n",
      "\n",
      "\n",
      "The column 'num_25' is already the type 'float64'.\n",
      "\n",
      "\n",
      "The column 'num_50' is already the type 'float64'.\n",
      "\n",
      "\n",
      "The column 'num_75' is already the type 'float64'.\n",
      "\n",
      "\n",
      "The column 'num_985' is already the type 'float64'.\n",
      "\n",
      "\n",
      "The column 'num_100' is already the type 'float64'.\n",
      "\n",
      "\n",
      "The column 'num_unq' is already the type 'float64'.\n",
      "\n",
      "\n",
      "The column 'total_secs' is already the type 'float64'.\n",
      "\n",
      "\n",
      "--- Analyzing user_logs.parquet DataFrame ---\n",
      "\n",
      "\n",
      "Displaying first 10 rows of the DataFrame:\n",
      "\n",
      "\n",
      "\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|    | msno                                         |   safra |   num_25 |   num_50 |   num_75 |   num_985 |   num_100 |   num_unq |   total_secs |\n",
      "+====+==============================================+=========+==========+==========+==========+===========+===========+===========+==============+\n",
      "|  0 | SwlrSivYHoKF9V5wm1YYYAnjHpd9y3OPjI9rDUhGJ3k= |  201701 |      121 |       28 |       14 |        29 |       704 |       827 |     184607   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  1 | rE5wSmHEF1Dhu55zhkiGB1HvotdlSHcIMGXv6VcqO2A= |  201605 |       26 |        2 |        5 |         6 |       462 |       256 |     119439   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  2 | hx+cyaQ/Jcdr/Z5foa/Cn0PXUzC/F7QO/NQvWQS1Qtc= |  201611 |      161 |       71 |       49 |        34 |       668 |       891 |     204791   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  3 | 53QW6B70J23X2UCvxaaUppjyE0b6X9nzP79W4huZv+Q= |  201502 |       37 |        9 |        3 |         9 |       408 |       447 |     101186   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  4 | /0S1N/oRyxGLZlzxnW5rOjfo0ZAls9EH23ahuDNuqz8= |  201506 |      205 |       49 |       23 |        21 |       225 |       489 |      69957.5 |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  5 | qB/zteXKaOk3hzFCoIUD6wrTp57hnreDX4Vvon25MfM= |  201509 |       52 |       10 |       10 |        20 |       308 |       264 |      81703.9 |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  6 | 7btpXOqzA1ggOggSW81L05zDYyDjO7dXgmwZVzYmI2Q= |  201610 |      159 |       53 |       30 |        43 |      1075 |       881 |     305354   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  7 | kgEhriAqTydVKQ1xn+ZzKQzf4sQ1aod5zcEg5ksyWrE= |  201609 |       88 |       13 |       14 |        13 |       588 |       325 |     159512   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  8 | 8uQ6M7OzdWsuzo0BRZ6siIPZfBoG43bRvlm+My36B6k= |  201509 |       62 |       27 |       15 |         6 |      1389 |      1427 |     324691   |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "|  9 | T2gUhlBhFMoSFA9jFI/BkuyE/EPA6oneabYQiGBy9wU= |  201702 |       36 |       23 |        5 |         9 |       216 |       241 |      56296.3 |\n",
      "+----+----------------------------------------------+---------+----------+----------+----------+-----------+-----------+-----------+--------------+\n",
      "\n",
      "\n",
      "\n",
      "Data types of columns in user_logs.parquet:\n",
      "\n",
      "\n",
      "msno          string[pyarrow]\n",
      "safra         string[pyarrow]\n",
      "num_25                float64\n",
      "num_50                float64\n",
      "num_75                float64\n",
      "num_985               float64\n",
      "num_100               float64\n",
      "num_unq               float64\n",
      "total_secs            float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Summary statistics for numeric columns: ['num_25', 'num_50', 'num_75', 'num_985', 'num_100', 'num_unq', 'total_secs']\n",
      "\n",
      "\n",
      "\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "|       |          num_25 |        num_50 |        num_75 |        num_985 |         num_100 |        num_unq |       total_secs |\n",
      "+=======+=================+===============+===============+================+=================+================+==================+\n",
      "| count |      2.6759e+07 |    2.6759e+07 |    2.6759e+07 |     2.6759e+07 |      2.6759e+07 |     2.6759e+07 |      2.6759e+07  |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| mean  |     95.426      |   24.0357     |   14.9035     |    16.5387     |    450.16       |   440.919      |     -2.11717e+13 |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| std   |    175.288      |   39.1255     |   22.6267     |    37.4092     |    725.314      |   590.606      |      6.83904e+14 |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| min   |      0          |    0          |    0          |     0          |      0          |     1          |     -2.39808e+17 |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| 25%   |      9          |    3          |    2          |     1          |     37          |    51          |  11174.2         |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| 50%   |     40          |   11          |    7          |     7          |    213          |   241          |  58868.6         |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| 75%   |    114          |   30          |   20          |    20          |    566          |   603          | 152769           |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "| max   | 111864          | 8875          | 3485          | 37698          | 196741          | 32706          |      9.22337e+15 |\n",
      "+-------+-----------------+---------------+---------------+----------------+-----------------+----------------+------------------+\n",
      "\n",
      "\n",
      "\n",
      "Missing values and their proportions per column:\n",
      "\n",
      "\n",
      "\n",
      "+------------+-----------------+--------------------------+\n",
      "|            |   Missing Count |   Missing Percentage (%) |\n",
      "+============+=================+==========================+\n",
      "| msno       |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| safra      |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| num_25     |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| num_50     |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| num_75     |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| num_985    |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| num_100    |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| num_unq    |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "| total_secs |               0 |                        0 |\n",
      "+------------+-----------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from src.log import configure_logging # Import the log module\n",
    "from src.prints import custom_print #Import the prints module\n",
    "from src.read_data import read_and_analyze_files, analyze_dask_dataframe  # Import the read_data module\n",
    "logger=None\n",
    "\n",
    "logger = configure_logging(log_dir='log')\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data', 'raw')\n",
    "\n",
    "file_names = ['members.parquet', 'transactions.parquet', 'user_logs.parquet']\n",
    "custom_print(logger, '1.Read and Analyze Data', space_lines=True)\n",
    "dict_df = read_and_analyze_files(data_dir, file_names, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_df=dict_df['user_logs.parquet']\n",
    "\n",
    "numeric_cols = dask_df.select_dtypes(include=[\"number\"]).columns\n",
    "summary_stats = dask_df.describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             num_25        num_50        num_75       num_985       num_100  \\\n",
      "count  2.675897e+07  2.675897e+07  2.675897e+07  2.675897e+07  2.675897e+07   \n",
      "mean   9.542601e+01  2.403567e+01  1.490352e+01  1.653867e+01  4.501598e+02   \n",
      "std    1.752883e+02  3.912555e+01  2.262672e+01  3.740916e+01  7.253139e+02   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    9.000000e+00  3.000000e+00  2.000000e+00  1.000000e+00  3.700000e+01   \n",
      "50%    4.000000e+01  1.100000e+01  7.000000e+00  7.000000e+00  2.130000e+02   \n",
      "75%    1.140000e+02  3.000000e+01  2.000000e+01  2.000000e+01  5.660000e+02   \n",
      "max    1.118640e+05  8.875000e+03  3.485000e+03  3.769800e+04  1.967410e+05   \n",
      "\n",
      "            num_unq    total_secs  \n",
      "count  2.675897e+07  2.675897e+07  \n",
      "mean   4.409193e+02 -2.117175e+13  \n",
      "std    5.906060e+02  6.839044e+14  \n",
      "min    1.000000e+00 -2.398077e+17  \n",
      "25%    5.100000e+01  1.117420e+04  \n",
      "50%    2.410000e+02  5.886861e+04  \n",
      "75%    6.030000e+02  1.527694e+05  \n",
      "max    3.270600e+04  9.223372e+15  \n"
     ]
    }
   ],
   "source": [
    "dask_df = dict_df['user_logs.parquet']\n",
    "\n",
    "# Seleciona colunas numéricas\n",
    "numeric_cols = dask_df.select_dtypes(include=[\"number\"]).columns.tolist()  # Converte para lista explícita\n",
    "\n",
    "# Calcula as estatísticas descritivas para as colunas numéricas\n",
    "summary_stats = dask_df[numeric_cols].describe().compute()\n",
    "\n",
    "# Exibe as estatísticas descritivas\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.675897e+07</td>\n",
       "      <td>2.675897e+07</td>\n",
       "      <td>2.675897e+07</td>\n",
       "      <td>2.675897e+07</td>\n",
       "      <td>2.675897e+07</td>\n",
       "      <td>2.675897e+07</td>\n",
       "      <td>2.675897e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.542601e+01</td>\n",
       "      <td>2.403567e+01</td>\n",
       "      <td>1.490352e+01</td>\n",
       "      <td>1.653867e+01</td>\n",
       "      <td>4.501598e+02</td>\n",
       "      <td>4.409193e+02</td>\n",
       "      <td>-2.117175e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.752883e+02</td>\n",
       "      <td>3.912555e+01</td>\n",
       "      <td>2.262672e+01</td>\n",
       "      <td>3.740916e+01</td>\n",
       "      <td>7.253139e+02</td>\n",
       "      <td>5.906060e+02</td>\n",
       "      <td>6.839044e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.398077e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.700000e+01</td>\n",
       "      <td>5.100000e+01</td>\n",
       "      <td>1.117420e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.130000e+02</td>\n",
       "      <td>2.410000e+02</td>\n",
       "      <td>5.886861e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.140000e+02</td>\n",
       "      <td>3.000000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>5.660000e+02</td>\n",
       "      <td>6.030000e+02</td>\n",
       "      <td>1.527694e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.118640e+05</td>\n",
       "      <td>8.875000e+03</td>\n",
       "      <td>3.485000e+03</td>\n",
       "      <td>3.769800e+04</td>\n",
       "      <td>1.967410e+05</td>\n",
       "      <td>3.270600e+04</td>\n",
       "      <td>9.223372e+15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_25        num_50        num_75       num_985       num_100  \\\n",
       "count  2.675897e+07  2.675897e+07  2.675897e+07  2.675897e+07  2.675897e+07   \n",
       "mean   9.542601e+01  2.403567e+01  1.490352e+01  1.653867e+01  4.501598e+02   \n",
       "std    1.752883e+02  3.912555e+01  2.262672e+01  3.740916e+01  7.253139e+02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    9.000000e+00  3.000000e+00  2.000000e+00  1.000000e+00  3.700000e+01   \n",
       "50%    4.000000e+01  1.100000e+01  7.000000e+00  7.000000e+00  2.130000e+02   \n",
       "75%    1.140000e+02  3.000000e+01  2.000000e+01  2.000000e+01  5.660000e+02   \n",
       "max    1.118640e+05  8.875000e+03  3.485000e+03  3.769800e+04  1.967410e+05   \n",
       "\n",
       "            num_unq    total_secs  \n",
       "count  2.675897e+07  2.675897e+07  \n",
       "mean   4.409193e+02 -2.117175e+13  \n",
       "std    5.906060e+02  6.839044e+14  \n",
       "min    1.000000e+00 -2.398077e+17  \n",
       "25%    5.100000e+01  1.117420e+04  \n",
       "50%    2.410000e+02  5.886861e+04  \n",
       "75%    6.030000e+02  1.527694e+05  \n",
       "max    3.270600e+04  9.223372e+15  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique genders per file: {'members.parquet': 2, 'transactions.parquet': None, 'user_logs.parquet': None}\n"
     ]
    }
   ],
   "source": [
    "def count_unique_genders(dict_df):\n",
    "    \"\"\"\n",
    "    Conta os gêneros únicos em todos os DataFrames dentro do dict_df.\n",
    "\n",
    "    Parameters:\n",
    "    dict_df (dict): Dicionário contendo DataFrames.\n",
    "\n",
    "    Returns:\n",
    "    dict: Dicionário com o número de gêneros únicos por arquivo.\n",
    "    \"\"\"\n",
    "    unique_genders = {}\n",
    "    for file_name, df in dict_df.items():\n",
    "        if 'gender' in df.columns:\n",
    "            unique_count = df['gender'].nunique().compute()  # Conta valores únicos na coluna 'gender'\n",
    "            unique_genders[file_name] = unique_count\n",
    "        else:\n",
    "            unique_genders[file_name] = None  # Marca como None se a coluna não existir\n",
    "\n",
    "    return unique_genders\n",
    "\n",
    "# Chamada da função\n",
    "unique_genders = count_unique_genders(dict_df)\n",
    "print(\"Unique genders per file:\", unique_genders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlogger\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from src.log import configure_logging # Import the log module\n",
    "from src.prints import custom_print #Import the prints module\n",
    "from src.read_data import read_and_analyze_files, analyze_dask_dataframe  # Import the read_data module\n",
    "logger=None\n",
    "logger = configure_logging(log_dir='log')\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data', 'raw')\n",
    "file_names = ['members.parquet', 'transactions.parquet', 'user_logs.parquet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading members.parquet\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Reading file: c:\\Users\\Lucas\\OneDrive\\case data master\\data\\raw\\members.parquet\n",
      "\n",
      "\n",
      "Reading transactions.parquet\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Reading file: c:\\Users\\Lucas\\OneDrive\\case data master\\data\\raw\\transactions.parquet\n",
      "\n",
      "\n",
      "Reading user_logs.parquet\n",
      "\n",
      "\n",
      "______________________________________________________________________________________________________________________________________________________\n",
      "Reading file: c:\\Users\\Lucas\\OneDrive\\case data master\\data\\raw\\user_logs.parquet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.read_data import read_and_analyze_files, analyze_dask_dataframe, read_parquet_file  # Import the read_data module\n",
    "\n",
    "for file_name in file_names:\n",
    "    custom_print(logger,f\"Reading {file_name}\")\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    dask_df = read_parquet_file(file_path, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dask_df['msno'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "msno          string[pyarrow]\n",
       "safra                   int32\n",
       "num_25                float64\n",
       "num_50                float64\n",
       "num_75                float64\n",
       "num_985               float64\n",
       "num_100               float64\n",
       "num_unq               float64\n",
       "total_secs            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df['members.parquet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Sabendo que existe a seguinte ação de retenção\n",
    "para clientes: Quando detectamos que um cliente\n",
    "não renova a assinatura, oferecemos 3 meses\n",
    "grátis. Porém, identificamos que essa ação é muito\n",
    "reativa e entendemos que uma abordagem\n",
    "proativa seria mais efetiva.\n",
    "Sendo assim, é proposto que você crie um modelo\n",
    "classificador para prever clientes que serão churn 3\n",
    "meses no futuro (ou seja, clientes que possuem\n",
    "assinatura ativa no período analisado e 3 meses\n",
    "depois desse período ele não é mais ativo, ou\n",
    "porque cancelou ou não renovou a assinatura) e\n",
    "indique os clientes que serão direcionados para a\n",
    "ação de forma proativa.\n",
    "1\n",
    "6\n",
    "Assumindo que, usando a ação de forma proativa,\n",
    "50% dos clientes que iriam cancelar (Verdadeiro\n",
    "Positivo) respondem de forma positiva e\n",
    "continuam ativos por mais um ano, qual sua\n",
    "avaliação sobre sua solução?\n",
    "Mínimo esperado:\n",
    "- Criação de target;\n",
    "- Feature Engineering;\n",
    "- Feature Selection;\n",
    "- Predictive Modeling;\n",
    "- Quantidade de clientes retidos e resultado\n",
    "financeiro da ação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "def create_churn_target_dask(transactions_df):\n",
    "    \"\"\"\n",
    "    Cria uma coluna 'is_churn' no DataFrame das transações que indica se o usuário terá churn após três meses.\n",
    "    \n",
    "    Parâmetros:\n",
    "    transactions_df (dd.DataFrame): DataFrame do Dask contendo as transações dos usuários com as seguintes colunas:\n",
    "                                    'msno', 'membership_expire_date', 'transaction_date', 'is_cancel'.\n",
    "    \n",
    "    Retorna:\n",
    "    dd.DataFrame: DataFrame com a coluna 'is_churn' adicionada.\n",
    "    \"\"\"\n",
    "    # Converte as datas de string para datetime\n",
    "    transactions_df['membership_expire_date'] = dd.to_datetime(transactions_df['membership_expire_date'], format='%Y%m%d')\n",
    "    transactions_df['transaction_date'] = dd.to_datetime(transactions_df['transaction_date'], format='%Y%m%d')\n",
    "    \n",
    "    # Define a data limite para observação de churn (última data de coleta de dados + 3 meses)\n",
    "    max_date = transactions_df['transaction_date'].max().compute()\n",
    "    churn_observation_date = max_date + timedelta(days=90)\n",
    "    \n",
    "    # Agrupa por usuário e pega a última data de expiração\n",
    "    last_expiration = transactions_df.groupby('msno')['membership_expire_date'].max().reset_index()\n",
    "    \n",
    "    # Identifica os usuários com churn: aqueles cuja última expiração é anterior à data de observação de churn\n",
    "    last_expiration['is_churn'] = last_expiration['membership_expire_date'].map(lambda x: 1 if x < churn_observation_date else 0)\n",
    "    \n",
    "    # Junta o resultado com o DataFrame original para marcar todos os registros de cada usuário\n",
    "    transactions_df = transactions_df.merge(last_expiration[['msno', 'is_churn']], on='msno', how='left')\n",
    "    \n",
    "    return transactions_df\n",
    "\n",
    "def create_churn_target_dask(transactions_df):\n",
    "    \"\"\"\n",
    "    Cria uma coluna 'is_churn' no DataFrame das transações que indica se o usuário terá churn após três meses da expiração.\n",
    "    \n",
    "    Parâmetros:\n",
    "    transactions_df (dd.DataFrame): DataFrame do Dask contendo as transações dos usuários.\n",
    "    \n",
    "    Retorna:\n",
    "    dd.DataFrame: DataFrame com a coluna 'is_churn' adicionada.\n",
    "    \"\"\"\n",
    "    # Converte as datas de string para datetime e ajusta categorias\n",
    "    transactions_df['membership_expire_date'] = dd.to_datetime(transactions_df['membership_expire_date'], format='%Y%m%d')\n",
    "    transactions_df['transaction_date'] = dd.to_datetime(transactions_df['transaction_date'], format='%Y%m%d')\n",
    "    transactions_df['payment_method_id'] = transactions_df['payment_method_id'].astype('category')\n",
    "    transactions_df['is_auto_renew'] = transactions_df['is_auto_renew'].astype('category')\n",
    "    transactions_df['is_cancel'] = transactions_df['is_cancel'].astype('category')\n",
    "\n",
    "    # Define a janela de observação de churn\n",
    "    def calculate_churn(exp_date, max_trans_date):\n",
    "        # A janela de observação começa após 3 meses da data de expiração\n",
    "        churn_observation_date = exp_date + timedelta(days=90)\n",
    "        return int(churn_observation_date > max_trans_date)\n",
    "\n",
    "    # Agrupa por usuário e calcula a última data de expiração\n",
    "    last_expiration = transactions_df.groupby('msno')['membership_expire_date'].max().reset_index()\n",
    "    \n",
    "    # Determina o churn com base na janela de observação\n",
    "    max_date = transactions_df['transaction_date'].max().compute()  # Data máxima de transação\n",
    "    last_expiration['is_churn'] = last_expiration['membership_expire_date'].apply(calculate_churn, args=(max_date,), meta=('x', 'int'))\n",
    "\n",
    "    # Junta os dados de churn com o DataFrame original\n",
    "    transactions_df = transactions_df.merge(last_expiration[['msno', 'is_churn']], on='msno', how='left')\n",
    "\n",
    "    return transactions_df\n",
    "\n",
    "transactions_df=create_churn_target_dask(dict_df['transactions.parquet'])\n",
    "\n",
    "analyze_dask_dataframe(dask_df=transactions_df, name='transactions_target', logger=logger)\n",
    "\n",
    "transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.read_data import read_and_analyze_files, analyze_dask_dataframe  # Import the read_data module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- `transactions.csv` gives us details like *payment method* or whether the subscription was cancelled.\n",
    "\n",
    "- `user_logs.csv` contains the listening behaviour of a user in terms of number of songs played.\n",
    "\n",
    "- `members.csv` includes the user's age, city, and such for users that have these membership information.\n",
    "\n",
    "Next is the **members** data:\n",
    "\n",
    "```{r}\n",
    "summary(members)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "glimpse(members)\n",
    "```\n",
    "\n",
    "We find:\n",
    "\n",
    "- In total 21 *Cities* are encoded by integers (there's no \"2\"). A factor encoding would make more sense here.\n",
    "\n",
    "- The *bd* feature is the age of the user (according to the [data description](https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data)) and contains clear outliers.\n",
    "\n",
    "- The *gender* is given by a character string and appears to contain quite a lot of missing entries.\n",
    "\n",
    "- *Registered\\_via* is a registration method that can probably also be factor encoded. The minimum is 3 and the maximum is 16. Both features contain values that lie well outside our prediction range.\n",
    "\n",
    "- The *registration_init_time* and *expiration_date* are date columns that should be encoded accordingly.\n",
    "\n",
    "\n",
    "Now we check the **transactions** data set:\n",
    "\n",
    "```{r}\n",
    "summary(trans)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "glimpse(trans)\n",
    "```\n",
    "\n",
    "We find:\n",
    "\n",
    "- The *payment\\_method\\_id* is encoded in integers from 2 to 41, with 41 being the median and therefore the most popular single method.\n",
    "\n",
    "- The feature *payment\\_plan\\_days* measures the length of membership subscription in days. Part of the difficulty in this challenge stems from the [subscription model of KKBox](https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data): Typically, a user would subscribe only for 30 days at a time (the median) and if wishing so re-subscribe every month; automatically or manually. Values here go up to 450 days.\n",
    "\n",
    "- In *plan\\_list\\_price* and *actual\\_amout\\_paid* we can see the theoretical and actual subscription price in units of New Taiwan Dollar (NTD). The values of both features range from 0-2000 NTD, with the *actual* mean being slightly higher than the *list* mean.\n",
    "\n",
    "- The feature *is_auto_renew* is a binary flag (encoded as integer) that shows a transaction was an automatic renewal of a user subscription. Judging from the integer mean of 0.85 a large majority of users take this option.\n",
    "\n",
    "- Again we have two date-type features: *transaction\\_date* and *membership\\_expire\\_date*. Those are important for determining whether a user has churned. In this challenge the [definition of churn](https://www.kaggle.com/c/kkbox-churn-prediction-challenge/data) is \"no new valid service subscription within 30 days after the current membership expires.\"\n",
    "\n",
    "- The feature *is\\_cancel* indicates a user cancellation in this transaction. This could lead to churn or to a new subscription plan.\n",
    "\n",
    "\n",
    "Finally, let's look at our sample of the **user\\_logs** data which records the listening behaviour:\n",
    "\n",
    "```{r}\n",
    "summary(logs)\n",
    "```\n",
    "\n",
    "```{r}\n",
    "glimpse(logs)\n",
    "```\n",
    "\n",
    "We find:\n",
    "\n",
    "- We have another *date* column reaching from Jan 2015 to the end of Feb 2017 (in this sample).\n",
    "\n",
    "- The integer features *num\\_25*, *num\\_50*, *num\\_75*, *num\\_985*, and *num\\_100* tell us the *number of songs* for this day that the user played for <25%, 25-50%, 50-75%, 75-98.5%, or >98.5% of their total duration. In other words: whether they liked the songs they heard. An interesting pattern can already be seen in the maxima of these features which decline from <25% to a local minimum at 50-75% only to rise again toward >98.5%. In general, the medians of these features are between 0 and 2, except for the full songs being played (*num\\_100*) where it is 17.\n",
    "\n",
    "- In *num\\_unq* we have encoded the number of unique songs played on by this user on that day. The median is 30.\n",
    "\n",
    "- The feature *total\\_sec* gives us the total number of seconds of music played per user per day. Be aware that there are a few spurious entries with highly negative or positive values:\n",
    "\n",
    "```{r}\n",
    "logs %>%\n",
    "  filter(abs(total_secs) > 1e10) %>%\n",
    "  select(total_secs) %>%\n",
    "  arrange(desc(total_secs)) %>%\n",
    "  head(4)\n",
    "\n",
    "logs %>%\n",
    "  filter(abs(total_secs) > 1e10) %>%\n",
    "  nrow()\n",
    "```\n",
    "\n",
    "## Missing values\n",
    "\n",
    "There are no NAs in our data samples.\n",
    "\n",
    "```{r}\n",
    "sum(is.na(train))\n",
    "sum(is.na(members))\n",
    "sum(is.na(trans))\n",
    "sum(is.na(logs))\n",
    "```\n",
    "\n",
    "\n",
    "## Reformating features\n",
    "\n",
    "```{r}\n",
    "train <- train %>%\n",
    "  mutate(is_churn = factor(is_churn))\n",
    "\n",
    "members <- members %>%\n",
    "  mutate(city = factor(city),\n",
    "         gender = factor(gender),\n",
    "         reg_via = factor(registered_via),\n",
    "         reg_init = ymd(registration_init_time))\n",
    "\n",
    "trans <- trans %>%\n",
    "  mutate(pay_met = factor(payment_method_id),\n",
    "         auto_renew = factor(is_auto_renew),\n",
    "         is_cancel = factor(is_cancel),\n",
    "         trans_date = ymd(transaction_date),\n",
    "         exp_date = ymd(membership_expire_date))\n",
    "\n",
    "logs <- logs %>%\n",
    "  mutate(date = ymd(date))\n",
    "```\n",
    "\n",
    "\n",
    "# Individual feature visualisations\n",
    "\n",
    "\n",
    "\n",
    "In a first step, we look at the various data sets individually. Of course, all the data is related and we will study these relations afterwards. But first things first.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
